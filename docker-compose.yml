services:

  api:
    image: api
    container_name: api
    build:
      context: ./api/ChatBotAPI
      dockerfile: Dockerfile
    ports:
      - 8080:8080 #http
      - 8081:8081 #https  
    depends_on:
      - qdrant
      - ai-chatbot
      - bge-m3
    links:
      - qdrant
      - ai-chatbot
      - bge-m3
    restart: always
    networks:
      - ai-chatbot-docker

  qdrant:
    image: qdrant/qdrant
    container_name: qdrant 
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
    ports:
      - 6333:6333 # tcp
      - 6334:6334 # grpc
    volumes:
      - ./qdrant_data:/qdrant/storage
    restart: always
    networks:
      - ai-chatbot-docker

  ai-chatbot:
    image: ollama/ollama:latest
    build:
      context: ./model_files
      dockerfile: Dockerfile.ai_chatbot
    ports:
      - 11434:11434
    volumes:
      - ./model_files:/model_files
      - ./ai-chatbot/ollama:/root/.ollama
    container_name: ai-chatbot
    pull_policy: always
    tty: true
    restart: always
    environment:
      - "OLLAMA_KEEP_ALIVE=24h"
      - "OLLAMA_HOST=0.0.0.0"
    healthcheck:
      test: "ollama --version && ollama ps || exit 1"
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - ai-chatbot-docker

  bge-m3:
    image: ollama/ollama:latest
    build:
      context: ./model_files
      dockerfile: Dockerfile.bge_m3
    ports:
      - 11435:11434
    volumes:
      - ./model_files:/model_files
      - ./bge-m3/ollama:/root/.ollama
    container_name: bge-m3
    pull_policy: always
    tty: true
    restart: always
    environment:
      - "OLLAMA_KEEP_ALIVE=24h"
      - "OLLAMA_HOST=0.0.0.0"
    healthcheck:
      test: "ollama --version && ollama ps || exit 1"
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - ai-chatbot-docker

volumes:
    bge-m3:
    ai-chatbot:
    qdrant_data:

networks:
  ai-chatbot-docker:
    external: false